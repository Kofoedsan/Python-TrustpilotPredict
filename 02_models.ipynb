{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 models\n",
    "\n",
    "Træn & sammenlign fasttext med sklearn på samme dataset og se hvilken model der er mest præcis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "\n",
    "- lav træningenfilen til en variabel. så vi kan bruge forskellige csv filer til træning\n",
    "- oprydning\n",
    "- QOL barplot på resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion der kan bruges til at installere manglende packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Installér fasttext\n",
    "install('tabulate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import fasttext\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Sklearn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=10000, probability=True, random_state=32, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/sklearn.csv\")\n",
    "df.head()\n",
    "\n",
    "#Term Frequency — Inverse Document Frequency\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "x = df['review']\n",
    "y = df['rating']\n",
    "\n",
    "x = tfidf.fit_transform(x)\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2, random_state=5)\n",
    "\n",
    "clf=SVC(kernel='linear',probability=True, random_state=32, decision_function_shape='ovr',max_iter=10000)\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FastText model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "#model = fasttext.train_supervised(input=\"./data/sklearn.csv\", epoch=32, lr=0.5, wordNgrams=2, bucket=200000, dim=30, loss='ova')\n",
    "model = fasttext.load_model('./data/fasttext_trained_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤══════════════════╤═══════════════════╤═════════════════════╤════════════════════╤══════════════════════╕\n",
      "│   stars  │   total reviews  │   sklearn predict │    sklearn accuracy │   fastText predict │    fasttext accuracy │\n",
      "╞══════════╪══════════════════╪═══════════════════╪═════════════════════╪════════════════════╪══════════════════════╡\n",
      "│        5 │             1879 │              2035 │                91.7 │               1918 │                97.92 │\n",
      "╘══════════╧══════════════════╧═══════════════════╧═════════════════════╧════════════════════╧══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "z = df['review']\n",
    "\n",
    "sklearnList = []\n",
    "fasttextList = []\n",
    "for line in z:\n",
    "    fasttextList.append(model.predict(line))\n",
    "    vec1 = tfidf.transform([line])\n",
    "    sklearnList.append(clf.predict(vec1))\n",
    "\n",
    "labelToTest = '__label__5 ' \n",
    "\n",
    "selectLabels = [labelToTest]\n",
    "label = df[df['rating'].isin(selectLabels)]\n",
    "# print('Total amount of reviews that gotten', labelToTest,len(label))\n",
    "\n",
    "sk = list(filter(lambda k: labelToTest in k, sklearnList))\n",
    "# print('Total amount of ', labelToTest + 'according to sklearn' , len(sk))\n",
    "\n",
    "fasttextLabels = []\n",
    "for index in fasttextList:\n",
    "    rep = str(index[0])\n",
    "    l = rep.split(\"'\")\n",
    "    l = l[1]+\" \"\n",
    "    fasttextLabels.append(l)\n",
    "\n",
    "ft = list(filter(lambda k: labelToTest in k, fasttextLabels))\n",
    "# print('Total amount of ', labelToTest + 'according to fasttext' , len(ft))\n",
    "\n",
    "def calc_accuracy(data):\n",
    "    if(data > 100):\n",
    "        data = 100 - data + 100\n",
    "        return data\n",
    "    else: \n",
    "        data = data - 100 + 100\n",
    "        return data      \n",
    "\n",
    "\n",
    "hundredp = len(label)\n",
    "\n",
    "roundft = len(ft)/hundredp*100\n",
    "roundsk = len(sk)/hundredp*100\n",
    "\n",
    "\n",
    "roundft = calc_accuracy(roundft)\n",
    "roundsk = calc_accuracy(roundsk)    \n",
    "\n",
    "# print('Accurary in % for fasttext' ,round(roundft,2),'%')\n",
    "# print('Accurary in % for sklearn' ,round(roundsk,2),\"%\")\n",
    "table = [['stars ','total reviews ', 'sklearn predict',' sklearn accuracy', 'fastText predict', ' fasttext accuracy' ], [labelToTest[-2] , len(label), len(sk),(round(roundsk,2)), len(ft), round(roundft,2) ]]\n",
    "print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
