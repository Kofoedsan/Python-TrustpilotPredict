{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Evaluate fastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- auto split train and valid\n",
    "- auto epoch\n",
    "- print samples (DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hjælpefunktion til at omregne til procent\n",
    "def to_perc(a, b):\n",
    "    return a / (a+b) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion til at returnére den mest optimale epoch iteration af datasættet\n",
    "def model_trainer():\n",
    "    models_train = []\n",
    "    models_valid = []\n",
    "    peak_epoch = 0\n",
    "    peak_value = 0.0\n",
    "\n",
    "    with tqdm(total=epoch+1) as progress:\n",
    "        for i in range(1, epoch+1):\n",
    "            progress.update(1)\n",
    "\n",
    "            model = fasttext.train_supervised(input=data_train, epoch=i, lr=lr, wordNgrams=wordNgrams, bucket=bucket, dim=dim, loss=loss)\n",
    "\n",
    "            models_train.append(model.test(data_train, k=top_labels))\n",
    "            models_valid.append(model.test(data_valid, k=top_labels))\n",
    "            \n",
    "            if (len(models_train) == 1):\n",
    "                print('             Training  |    Validation')\n",
    "                print('        ', '{0:6}'.format(models_train[i-1][0]), '{:.1f}'.format(to_perc(models_train[i-1][0], models_valid[i-1][0])) + '%',\n",
    "                      ' | ', '{0:6}'.format(models_valid[i-1][0]), '{:.1f}'.format(to_perc(models_valid[i-1][0], models_train[i-1][0])) + '%')\n",
    "                print('                       |')\n",
    "                print('Epoch   ', 'Prec.', 'Recall  | ', 'Prec.', 'Recall')\n",
    "                print('-----------------------+---------------------------')\n",
    "            \n",
    "            if (models_valid[i-1][1] > peak_value):\n",
    "                peak_value = models_valid[i-1][1]\n",
    "                peak_epoch = i\n",
    "                precision = '\\033[92mHigher\\033[0m'\n",
    "            else:\n",
    "                precision = '\\033[91mLower\\033[0m'\n",
    "\n",
    "            print('{0:2}'.format(i), ' ==> ', '{:.3f}'.format(models_train[i-1][1]), ' {:.3f}'.format(models_train[i-1][2]),\n",
    "                  ' |', ' {:.3f}'.format(models_valid[i-1][1]), ' {:.3f}'.format(models_valid[i-1][2]), ' ==> ', precision)\n",
    "\n",
    "        print('\\n    -->  Epoch peaked at', '\\033[1m' + '\\033[94m' + str(peak_epoch))\n",
    "\n",
    "        model = fasttext.train_supervised(input=data_train, epoch=peak_epoch, lr=lr, wordNgrams=wordNgrams, bucket=bucket, dim=dim, loss=loss)\n",
    "        model.save_model('./data/fasttext_trained_model.bin')\n",
    "        \n",
    "        return peak_epoch, models_train, models_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisér modellen via plotting\n",
    "def model_plot(title, i, model_valid_epoch, models_train, models_valid):\n",
    "    threshold = 0.2\n",
    "    y_range_min = min([y[i] for y in models_valid if y[i] > threshold])\n",
    "    y_range_max = max([y[i] for y in models_train if y[i] > threshold])\n",
    "    \n",
    "    plt.plot([pr[i] for pr in models_train], label='Training')\n",
    "    plt.plot([pr[i] for pr in models_valid], label='Validation')\n",
    "    plt.axvline(model_valid_epoch, linewidth=2, color='g', linestyle='--', label=('Epoch Peak'))\n",
    "\n",
    "    plt.title('Model (' + title + ')')\n",
    "    plt.ylabel(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.ylim([y_range_min, y_range_max+0.01])\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be24d3fe181414799be49bd8f2aeafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Training  |    Validation\n",
      "           4998 69.2%  |    2229 30.8%\n",
      "                       |\n",
      "Epoch    Prec. Recall  |  Prec. Recall\n",
      "-----------------------+---------------------------\n",
      " 1  ==>  0.433  0.865  |  0.424  0.848  ==>  \u001b[92mHigher\u001b[0m\n",
      " 2  ==>  0.446  0.892  |  0.436  0.873  ==>  \u001b[92mHigher\u001b[0m\n",
      " 3  ==>  0.450  0.900  |  0.441  0.881  ==>  \u001b[92mHigher\u001b[0m\n",
      " 4  ==>  0.453  0.906  |  0.444  0.889  ==>  \u001b[92mHigher\u001b[0m\n",
      " 5  ==>  0.454  0.907  |  0.447  0.894  ==>  \u001b[92mHigher\u001b[0m\n",
      " 6  ==>  0.454  0.907  |  0.448  0.897  ==>  \u001b[92mHigher\u001b[0m\n",
      " 7  ==>  0.455  0.909  |  0.450  0.900  ==>  \u001b[92mHigher\u001b[0m\n",
      " 8  ==>  0.456  0.913  |  0.451  0.903  ==>  \u001b[92mHigher\u001b[0m\n",
      " 9  ==>  0.459  0.919  |  0.453  0.905  ==>  \u001b[92mHigher\u001b[0m\n",
      "10  ==>  0.464  0.928  |  0.456  0.913  ==>  \u001b[92mHigher\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Træn modellen ud fra givne parameter\n",
    "data_train = './data/test.train'\n",
    "data_valid = './data/test.valid'\n",
    "epoch      = 30\n",
    "lr         = 0.2\n",
    "wordNgrams = 2\n",
    "bucket     = 20000\n",
    "dim        = 100\n",
    "loss       = 'ova'\n",
    "top_labels = 2\n",
    "\n",
    "mt = model_trainer()\n",
    "model_plot('Precision', 1, mt[0], mt[1], mt[2])\n",
    "model_plot('Recall', 2, mt[0], mt[1], mt[2])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
