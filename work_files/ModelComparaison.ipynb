{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import fasttext\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"sklearn.csv\")\n",
    "\n",
    "#Begge modeller skal være trænet med samme datasæt for at give en fair sammenligning!!\n",
    "with open('sklearn', 'rb') as file:\n",
    "      \n",
    "    sklearn = pickle.load(file)\n",
    "\n",
    "model = fasttext.load_model(\"fasttext.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3640x10203 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 144608 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "x = df['review']\n",
    "tfidf.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearnList = []\n",
    "fasttextList = []\n",
    "for line in x:\n",
    "    fasttextList.append(model.predict(line))\n",
    "    vec1 = tfidf.transform([line])\n",
    "    sklearnList.append(sklearn.predict(vec1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelToTest = '__label__5 '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of reviews that gotten __label__5  1880\n"
     ]
    }
   ],
   "source": [
    "selectLabels = [labelToTest]\n",
    "label = df[df['rating'].isin(selectLabels)]\n",
    "print('Total amount of reviews that gotten', labelToTest,len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of  __label__5 according to sklearn 2044\n"
     ]
    }
   ],
   "source": [
    "sk = list(filter(lambda k: labelToTest in k, sklearnList))\n",
    "print('Total amount of ', labelToTest + 'according to sklearn' , len(sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of  __label__5 according to fasttext 1895\n"
     ]
    }
   ],
   "source": [
    "fasttextLabels = []\n",
    "for index in fasttextList:\n",
    "    rep = str(index[0])\n",
    "    l = rep.split(\"'\")\n",
    "    l = l[1]+\" \"\n",
    "    fasttextLabels.append(l)\n",
    "\n",
    "ft = list(filter(lambda k: labelToTest in k, fasttextLabels))\n",
    "print('Total amount of ', labelToTest + 'according to fasttext' , len(ft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data):\n",
    "    if(data > 100):\n",
    "        data = 100 - data + 100\n",
    "        return data\n",
    "    else: \n",
    "        data = data - 100 + 100\n",
    "        return data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary in % for fasttext 99.2 %\n",
      "Accurary in % for sklearn 91.28 %\n"
     ]
    }
   ],
   "source": [
    "hundredp = len(label)\n",
    "\n",
    "roundft = len(ft)/hundredp*100\n",
    "roundsk = len(sk)/hundredp*100\n",
    "\n",
    "\n",
    "roundft = calc_accuracy(roundft)\n",
    "roundsk = calc_accuracy(roundsk)    \n",
    "\n",
    "print('Accurary in % for fasttext' ,round(roundft,2),'%')\n",
    "print('Accurary in % for sklearn' ,round(roundsk,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
