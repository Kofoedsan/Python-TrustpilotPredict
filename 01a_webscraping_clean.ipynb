{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Webscraping Clean\n",
    "\n",
    "#### Rens og filtrér hentet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import csv\n",
    "import requests\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "reviewErrorCount = [] # used in multithreadwritecsvfile\n",
    "dataDir = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRawData(*args):\n",
    "    allPagesRequest = []\n",
    "    for arg in args:\n",
    "        with open(dataDir+arg+'.dump','rb') as file:\n",
    "            allPagesRequest = allPagesRequest + pickle.load(file)\n",
    "    return allPagesRequest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frasortere emojis\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "# Frasortere linjeskift, comma, og dobbelt mellemrum & gør al tekst lowercase.\n",
    "def data_cleaning(data):\n",
    "    data = data.lower()\n",
    "    data = data.replace('\\r', ' ')\n",
    "    data = data.replace(\",\", ' ')\n",
    "    data = data.replace('\"', '')\n",
    "    data = data.replace('  ', '')\n",
    "    return data\n",
    "\n",
    "# Splitter hver url i listen, og returnere hjemmesidenavnet.\n",
    "def createFiles(url):\n",
    "    filename = str(url.url)\n",
    "    filename = filename.split('.')\n",
    "\n",
    "    if len(filename) == 4:\n",
    "        filename = filename[2].split('/')\n",
    "        filename = filename[2]\n",
    "    else:\n",
    "        filename = filename[3]\n",
    "    return filename\n",
    "\n",
    "# Tjekker om filen eksistere, så den ikke bliver appended til igen. \n",
    "def checkFileExists(filename):\n",
    "    try:\n",
    "        with open(filename,'rb') as file:\n",
    "            return 0\n",
    "    except:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtrere den gå data med bs4 og skriver til en csv med det navn som request url'et indholder.\n",
    "def multithreadwritecsvfile(page):\n",
    "    loadingbar.update(1)\n",
    "\n",
    "    filename = dataDir+createFiles(page)+'.csv'\n",
    "    \n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as output_file:\n",
    "        output_writer = csv.writer(output_file)\n",
    "        \n",
    "        soup = bs4.BeautifulSoup(page.content,'html.parser')\n",
    "        for content in soup.find_all('section', attrs={'class':'styles_reviewContentwrapper__zH_9M'}):\n",
    "            rating=None\n",
    "            splitted=None\n",
    "            review=None\n",
    "\n",
    "            try: \n",
    "                rating = content.find('img',alt = True)\n",
    "                splitted = rating.get('alt').split()\n",
    "            except Exception as e:\n",
    "                print('No rating found. Skipping...', e)\n",
    "\n",
    "            try: \n",
    "                review = content.find('p', attrs={'class':'typography_typography__QgicV typography_body__9UBeQ typography_color-black__5LYEn typography_weight-regular__TWEnf typography_fontstyle-normal__kHyN3'}).text\n",
    "                if len(review) > 2:\n",
    "                    review = remove_emojis(review)\n",
    "                    review = data_cleaning(review)\n",
    "                    if len(review) > 0:\n",
    "                        output_writer.writerow(['__label__'+splitted[2]+\" \", review])\n",
    "            except Exception as e:\n",
    "                reviewErrorCount.append(e);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get the list of files we have avaliable\n",
    "def get_filenames(ext):\n",
    "    pathname = dataDir + '/*.'+ext\n",
    "    filenames = []\n",
    "    for file in glob.glob(pathname, recursive=True):\n",
    "        file = file.replace('.dump','')\n",
    "        filenames.append(file.replace(dataDir,''))\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "def mergeCsvFiles(filenames_input):\n",
    "\n",
    "    filenames = []\n",
    "    # loop through the list with filenames we want to merge\n",
    "    for name in filenames_input:\n",
    "        filenames.append(dataDir+name + '.csv')\n",
    "\n",
    "    #combine all the files\n",
    "    combinedCSV = pd.concat([pd.read_csv(f) for f in filenames])\n",
    "    print(filenames)\n",
    "    \n",
    "    #export to csv\n",
    "    combinedCSV.to_csv(dataDir+'combined_csv.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alfinans',\n",
       " 'asos',\n",
       " 'boksen',\n",
       " 'contourdesign',\n",
       " 'cphbusiness',\n",
       " 'eboligskoedet',\n",
       " 'ferratumbank',\n",
       " 'gamecastle',\n",
       " 'isports',\n",
       " 'jyskmobelfabrik',\n",
       " 'sas',\n",
       " 'tapeconnection',\n",
       " 'thyrep',\n",
       " 'vestjyskbank']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filenames('dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/komplett.dump'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b360811894c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m  \u001b[0;34m'sas'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m  \u001b[0;34m'tapeconnection'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m  \u001b[0;34m'thyrep'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-2-683e67b85905>\u001b[0m in \u001b[0;36mloadRawData\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mallPagesRequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.dump'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mallPagesRequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallPagesRequest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mallPagesRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/komplett.dump'"
     ]
    }
   ],
   "source": [
    "allPagesRequest = loadRawData(\n",
    " 'boksen',\n",
    " 'contourdesign',\n",
    " 'cphbusiness',\n",
    " 'eboligskoedet',\n",
    " 'gamecastle',\n",
    " 'isports',\n",
    " 'jyskmobelfabrik',\n",
    " 'komplett',\n",
    " 'sas',\n",
    " 'tapeconnection',\n",
    " 'thyrep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allPagesRequest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-91ded1d1f8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mshop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallPagesRequest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcreateFiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moutput_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutput_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allPagesRequest' is not defined"
     ]
    }
   ],
   "source": [
    "for shop in allPagesRequest:\n",
    "    filename = dataDir+createFiles(shop)+'.csv'\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        output_writer = csv.writer(output_file)\n",
    "        output_writer.writerow(['rating','review'])\n",
    "        \n",
    "with tqdm(total=len(allPagesRequest)) as loadingbar: \n",
    "    with ThreadPoolExecutor(8) as ex:\n",
    "        \n",
    "        ex.map(multithreadwritecsvfile, allPagesRequest)\n",
    "\n",
    "print('Done. Skipped reviews:', len(reviewErrorCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alfinans.csv',\n",
       " 'asos.csv',\n",
       " 'av-cables.csv',\n",
       " 'boksen.csv',\n",
       " 'cdon.csv',\n",
       " 'combined_csv.csv',\n",
       " 'computersalg.csv',\n",
       " 'contourdesign.csv',\n",
       " 'cphbusiness.csv',\n",
       " 'eboligskoedet.csv',\n",
       " 'elgiganten.csv',\n",
       " 'ferratumbank.csv',\n",
       " 'gamecastle.csv',\n",
       " 'isports.csv',\n",
       " 'jyskmobelfabrik.csv',\n",
       " 'komplett.csv',\n",
       " 'power.csv',\n",
       " 'sas.csv',\n",
       " 'sklearn.csv',\n",
       " 'tapeconnection.csv',\n",
       " 'telia.csv',\n",
       " 'thyrep.csv',\n",
       " 'vestjyskbank.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filenames('csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/boksen.csv', './data/contourdesign.csv', './data/cphbusiness.csv', './data/eboligskoedet.csv', './data/gamecastle.csv', './data/isports.csv', './data/jyskmobelfabrik.csv', './data/komplett.csv', './data/sas.csv', './data/tapeconnection.csv', './data/thyrep.csv']\n"
     ]
    }
   ],
   "source": [
    "mergeCsvFiles([\n",
    " 'boksen',\n",
    " 'contourdesign',\n",
    " 'cphbusiness',\n",
    " 'eboligskoedet',\n",
    " 'gamecastle',\n",
    " 'isports',\n",
    " 'jyskmobelfabrik',\n",
    " 'komplett',\n",
    " 'sas',\n",
    " 'tapeconnection',\n",
    " 'thyrep'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
